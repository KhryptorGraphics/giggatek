# GigGatek Logstash Pipeline Configuration

input {
  # Collect logs from Filebeat
  beats {
    port => 5044
    ssl => false
  }

  # Collect logs via TCP (for direct application logging)
  tcp {
    port => 5000
    codec => json
  }

  # Collect logs via UDP (for syslog, etc)
  udp {
    port => 5000
    codec => json
  }

  # Collect logs from application files
  file {
    path => [
      "/var/log/apache2/*.log",
      "/var/log/nginx/*.log",
      "/var/log/mysql/*.log",
      "/opt/giggatek/logs/**/*.log"
    ]
    start_position => "beginning"
    sincedb_path => "/dev/null"
    type => "system_logs"
  }
}

filter {
  # Add host details to all events
  mutate {
    add_field => {
      "[@metadata][app]" => "giggatek"
    }
  }

  # Process Apache/Nginx access logs
  if [type] == "apache_access" or [fileset][name] == "access" {
    grok {
      match => { "message" => "%{COMBINEDAPACHELOG}" }
    }
    
    date {
      match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
      remove_field => [ "timestamp" ]
    }
    
    # Enrich with geolocation data if IP is present
    if [clientip] {
      geoip {
        source => "clientip"
        target => "geoip"
      }
    }
    
    # Parse user agent information
    useragent {
      source => "agent"
      target => "user_agent"
    }
  }
  
  # Process MySQL logs
  else if [type] == "mysql" or [fileset][name] == "error" {
    grok {
      match => { "message" => "%{TIMESTAMP_ISO8601:timestamp} %{NOTSPACE:thread_id} \[%{WORD:log_level}\] %{GREEDYDATA:log_message}" }
    }
    
    date {
      match => [ "timestamp", "ISO8601" ]
      remove_field => [ "timestamp" ]
    }
  }
  
  # Process PHP error logs
  else if [type] == "php_error" {
    grok {
      match => { "message" => "(?m)\[%{TIMESTAMP_ISO8601:timestamp}\] PHP %{WORD:log_level}: %{GREEDYDATA:log_message}" }
    }
    
    date {
      match => [ "timestamp", "ISO8601" ]
      remove_field => [ "timestamp" ]
    }
    
    mutate {
      add_field => { "[log][level]" => "%{log_level}" }
    }
  }
  
  # Process JSON formatted logs (e.g., from applications)
  else if [message] =~ /^\{.*\}$/ {
    json {
      source => "message"
    }
    
    if [timestamp] {
      date {
        match => [ "timestamp", "ISO8601", "UNIX", "UNIX_MS" ]
        remove_field => [ "timestamp" ]
      }
    }
  }
  
  # Set default index name based on application and date
  mutate {
    add_field => {
      "[@metadata][index]" => "giggatek-%{+YYYY.MM.dd}"
    }
  }
  
  # Add environment tag
  if [kubernetes][namespace] {
    mutate {
      add_field => {
        "environment" => "%{[kubernetes][namespace]}"
      }
    }
  } else {
    mutate {
      add_field => {
        "environment" => "${ENVIRONMENT:production}"
      }
    }
  }
}

output {
  # Send logs to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{[@metadata][index]}"
    
    # For better performance, batch documents together
    action => "index"
    
    # If Elasticsearch is temporarily unavailable, buffer events locally
    manage_template => false
    template_overwrite => false
  }
  
  # Optionally output to stdout for debugging
  if [loglevel] == "debug" {
    stdout {
      codec => rubydebug
    }
  }
}
